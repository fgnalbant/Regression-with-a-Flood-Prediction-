{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":73278,"databundleVersionId":8121328,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/gizemnalbantarslan/regression-with-a-flood-prediction?scriptVersionId=199070967\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"markdown","source":"# <p style=\"text-align:center;\"> Regression with a Flood Prediction Dataset </p>\n\n<span style=\"font-size:18px;\"> The goal of this competition is to predict the probability of a region flooding based on various factors. </span>","metadata":{}},{"cell_type":"code","source":"# import and requirements\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,accuracy_score\nfrom sklearn.model_selection import GridSearchCV,train_test_split,cross_validate, RandomizedSearchCV, validation_curve\nfrom sklearn.preprocessing import StandardScaler\n\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n# warnings.simplefilter(\"ignore\", category=ConvergenceWarning)\n\npd.set_option('display.max_columns', None)\npd.set_option('display.width', None)\npd.set_option('display.float_format', lambda x: '%.3f' % x)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:18.835478Z","iopub.execute_input":"2024-05-22T22:06:18.836285Z","iopub.status.idle":"2024-05-22T22:06:21.686841Z","shell.execute_reply.started":"2024-05-22T22:06:18.836248Z","shell.execute_reply":"2024-05-22T22:06:21.685713Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 1. Exploratory Data Analysis","metadata":{}},{"cell_type":"code","source":"train = pd.read_csv(\"../input/playground-series-s4e5/train.csv\")\ntr=train.copy()\ntest = pd.read_csv(\"../input/playground-series-s4e5/test.csv\")\nts=test.copy()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:21.688605Z","iopub.execute_input":"2024-05-22T22:06:21.689043Z","iopub.status.idle":"2024-05-22T22:06:24.962313Z","shell.execute_reply.started":"2024-05-22T22:06:21.689014Z","shell.execute_reply":"2024-05-22T22:06:24.961214Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 1.1 Definition of Functions\n\n<span style=\"font-size:18px;\">First of all, let's define our functions. The functions we will use here and their tasks are as follows: \n\n* <span style=\"font-size:18px;\"> **check_df :** An overview of the dataset\n* <span style=\"font-size:18px;\"> **cat_summary :** analysis of categorical variables\n* <span style=\"font-size:18px;\"> **num_summary :** review of numeric variables\n* <span style=\"font-size:18px;\"> **target_summary_with_num:** analysis of the relationship of numeric variables with the target variable\n* <span style=\"font-size:18px;\"> **target_summary_with_cat :** analyzing the relationship of categorical variables with the target variable\n* <span style=\"font-size:18px;\">**correlation_matrix:** analysis of correlations\n* <span style=\"font-size:18px;\"> **grab_col_names:** detailed categorization of variables </span>","metadata":{}},{"cell_type":"code","source":"def check_df(dataframe):\n    print(\"##################### Shape #####################\")\n    print(dataframe.shape)\n    print(\"##################### Types #####################\")\n    print(dataframe.dtypes)\n    print(\"##################### Head #####################\")\n    print(dataframe.head(3))\n    print(\"##################### Tail #####################\")\n    print(dataframe.tail(3))\n    print(\"##################### NA #####################\")\n    print(dataframe.isnull().sum())\n    print(\"##################### describe #####################\")\n    print(dataframe.describe())\n    print(\"##################### Quantiles #####################\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:24.967253Z","iopub.execute_input":"2024-05-22T22:06:24.967552Z","iopub.status.idle":"2024-05-22T22:06:24.973985Z","shell.execute_reply.started":"2024-05-22T22:06:24.967526Z","shell.execute_reply":"2024-05-22T22:06:24.972984Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def cat_summary(dataframe, col_name, plot=False):\n    print(pd.DataFrame({col_name: dataframe[col_name].value_counts(),\n                        \"Ratio\": 100 * dataframe[col_name].value_counts() / len(dataframe)}))\n    print(\"##########################################\")\n    if plot:\n        sns.countplot(x=dataframe[col_name], data=dataframe)\n        plt.show(block=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:24.975401Z","iopub.execute_input":"2024-05-22T22:06:24.975699Z","iopub.status.idle":"2024-05-22T22:06:24.987416Z","shell.execute_reply.started":"2024-05-22T22:06:24.975672Z","shell.execute_reply":"2024-05-22T22:06:24.986387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def num_summary(dataframe, numerical_col, plot=False):\n    quantiles = [0.05, 0.10, 0.20, 0.30, 0.40, 0.50, 0.60, 0.70, 0.80, 0.90, 0.95, 0.99]\n    print(dataframe[numerical_col].describe(quantiles).T)\n\n    if plot:\n        dataframe[numerical_col].hist(bins=20)\n        plt.xlabel(numerical_col)\n        plt.title(numerical_col)\n        plt.show(block=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:24.988622Z","iopub.execute_input":"2024-05-22T22:06:24.988932Z","iopub.status.idle":"2024-05-22T22:06:24.998179Z","shell.execute_reply.started":"2024-05-22T22:06:24.988906Z","shell.execute_reply":"2024-05-22T22:06:24.997285Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def target_summary_with_num(dataframe, target, numerical_col):\n    print(dataframe.groupby(target).agg({numerical_col: \"mean\"}), end=\"\\n\\n\\n\")\n\ndef target_summary_with_cat(dataframe, target, categorical_col):\n    print(pd.DataFrame({\"TARGET_MEAN\": dataframe.groupby(categorical_col)[target].mean()}), end=\"\\n\\n\\n\")","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:24.999392Z","iopub.execute_input":"2024-05-22T22:06:24.999677Z","iopub.status.idle":"2024-05-22T22:06:25.012375Z","shell.execute_reply.started":"2024-05-22T22:06:24.999652Z","shell.execute_reply":"2024-05-22T22:06:25.011423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def correlation_matrix(df, cols):\n    fig = plt.gcf()\n    fig.set_size_inches(20,20)\n    plt.xticks(fontsize=10)\n    plt.yticks(fontsize=10)\n    fig = sns.heatmap(df[cols].corr(), annot=False, linewidths=0.5, annot_kws={'size': 12}, linecolor='w', cmap='RdBu')\n    plt.show(block=True)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:25.013427Z","iopub.execute_input":"2024-05-22T22:06:25.013694Z","iopub.status.idle":"2024-05-22T22:06:25.022941Z","shell.execute_reply.started":"2024-05-22T22:06:25.013671Z","shell.execute_reply":"2024-05-22T22:06:25.022033Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def grab_col_names(dataframe, cat_th=10, car_th=20):\n\n    # cat_cols, cat_but_car\n    cat_cols = [col for col in dataframe.columns if dataframe[col].dtypes == \"O\"]\n    num_but_cat = [col for col in dataframe.columns if dataframe[col].nunique() < cat_th and\n                   dataframe[col].dtypes != \"O\"]\n    cat_but_car = [col for col in dataframe.columns if dataframe[col].nunique() > car_th and\n                   dataframe[col].dtypes == \"O\"]\n    cat_cols = cat_cols + num_but_cat\n    cat_cols = [col for col in cat_cols if col not in cat_but_car]\n\n    # num_cols\n    num_cols = [col for col in dataframe.columns if dataframe[col].dtypes != \"O\"]\n    num_cols = [col for col in num_cols if col not in num_but_cat]\n\n    # print(f\"Observations: {dataframe.shape[0]}\")\n    # print(f\"Variables: {dataframe.shape[1]}\")\n    # print(f'cat_cols: {len(cat_cols)}')\n    # print(f'num_cols: {len(num_cols)}')\n    # print(f'cat_but_car: {len(cat_but_car)}')\n    # print(f'num_but_cat: {len(num_but_cat)}')\n    return cat_cols, num_cols, cat_but_car","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:25.023974Z","iopub.execute_input":"2024-05-22T22:06:25.024264Z","iopub.status.idle":"2024-05-22T22:06:25.033048Z","shell.execute_reply.started":"2024-05-22T22:06:25.024238Z","shell.execute_reply":"2024-05-22T22:06:25.032181Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 1.2 Data Analysis","metadata":{}},{"cell_type":"code","source":"check_df(tr)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:25.036338Z","iopub.execute_input":"2024-05-22T22:06:25.036738Z","iopub.status.idle":"2024-05-22T22:06:26.361528Z","shell.execute_reply.started":"2024-05-22T22:06:25.03671Z","shell.execute_reply":"2024-05-22T22:06:26.360517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">There is no NA values and anomalous distribution in quantiles. </span>","metadata":{}},{"cell_type":"code","source":"cat_cols, num_cols, cat_but_car = grab_col_names(tr)\nnum_cols = [col for col in num_cols if col not in (\"FloodProbability\", \"id\")]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:26.362997Z","iopub.execute_input":"2024-05-22T22:06:26.363386Z","iopub.status.idle":"2024-05-22T22:06:26.735519Z","shell.execute_reply.started":"2024-05-22T22:06:26.363347Z","shell.execute_reply":"2024-05-22T22:06:26.734688Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> As we can see after this analysis, there is no categorical or cardinal variable in the data. All variables are in the numeric category.\nTherefore, let's do our analysis on numeric variables in the following processes </span>","metadata":{}},{"cell_type":"code","source":"# Analysis of num_cols with graphics\nplt.figure(figsize=(20, 20))\nfor col in num_cols:\n    plt.subplot(7, 3, num_cols.index(col) + 1)\n    sns.histplot(tr[col], bins=20)\n    plt.title(col)\nplt.tight_layout()\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:26.737069Z","iopub.execute_input":"2024-05-22T22:06:26.737436Z","iopub.status.idle":"2024-05-22T22:06:46.89291Z","shell.execute_reply.started":"2024-05-22T22:06:26.737402Z","shell.execute_reply":"2024-05-22T22:06:46.891819Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#correlation analysis of numerical variables\ncorrelation_matrix(tr, num_cols)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:46.894132Z","iopub.execute_input":"2024-05-22T22:06:46.894434Z","iopub.status.idle":"2024-05-22T22:06:49.037666Z","shell.execute_reply.started":"2024-05-22T22:06:46.894408Z","shell.execute_reply":"2024-05-22T22:06:49.036598Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target analysis of numerical variables\nfor col in num_cols:\n    target_summary_with_num(tr, \"FloodProbability\", col)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.038971Z","iopub.execute_input":"2024-05-22T22:06:49.039289Z","iopub.status.idle":"2024-05-22T22:06:49.721659Z","shell.execute_reply.started":"2024-05-22T22:06:49.039262Z","shell.execute_reply":"2024-05-22T22:06:49.720352Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 2. Data Preprocessing & Feature Engineering\n\n\n> # 2.1 Definition of Functions\n\n<span style=\"font-size:18px;\">We define the functions to prepare the data. \n\n* <span style=\"font-size:18px;\">**outlier_thresholds:** catches outliers.\n* <span style=\"font-size:18px;\">**replace_with_thresholds:** removes outliers from the dataset.\n* <span style=\"font-size:18px;\">**check_outlier:** checks if there is an outlier or not.</span>","metadata":{}},{"cell_type":"code","source":"def outlier_thresholds(dataframe, col_name, q1=0.25, q3=0.75):\n    quartile1 = dataframe[col_name].quantile(q1)\n    quartile3 = dataframe[col_name].quantile(q3)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.722842Z","iopub.execute_input":"2024-05-22T22:06:49.72313Z","iopub.status.idle":"2024-05-22T22:06:49.728755Z","shell.execute_reply.started":"2024-05-22T22:06:49.723105Z","shell.execute_reply":"2024-05-22T22:06:49.727684Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.730199Z","iopub.execute_input":"2024-05-22T22:06:49.730495Z","iopub.status.idle":"2024-05-22T22:06:49.739807Z","shell.execute_reply.started":"2024-05-22T22:06:49.730469Z","shell.execute_reply":"2024-05-22T22:06:49.738821Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"def check_outlier(dataframe, col_name, q1=0.25, q3=0.75):\n    low_limit, up_limit = outlier_thresholds(dataframe, col_name, q1, q3)\n    if dataframe[(dataframe[col_name] > up_limit) | (dataframe[col_name] < low_limit)].any(axis=None):\n        return True\n    else:\n        return False","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.741091Z","iopub.execute_input":"2024-05-22T22:06:49.741461Z","iopub.status.idle":"2024-05-22T22:06:49.750719Z","shell.execute_reply.started":"2024-05-22T22:06:49.741433Z","shell.execute_reply":"2024-05-22T22:06:49.74983Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 2.2 Definition of New Variables\n\n<span style=\"font-size:18px;\"> Let's extract new variables from existing variables and define all operations as a function so that we can easily perform operations for the test dataset. </span>","metadata":{}},{"cell_type":"code","source":"def add_features(dataframe):\n    dataframe[\"NEW_musdrasy\"] = dataframe[\"MonsoonIntensity\"] * dataframe[\"TopographyDrainage\"]\n    dataframe[\"NEW_musinefdis\"] = dataframe[\"MonsoonIntensity\"] * dataframe[\"IneffectiveDisasterPreparedness\"]\n    dataframe[\"NEW_musdrasy\"] = dataframe[\"MonsoonIntensity\"] * dataframe[\"DrainageSystems\"]\n    dataframe[\"NEW_musdeter\"] = dataframe[\"MonsoonIntensity\"] * dataframe[\"DeterioratingInfrastructure\"]\n    dataframe[\"NEW_deforlandsl\"] = dataframe[\"Deforestation\"] * dataframe[\"Landslides\"]\n    dataframe[\"NEW_deforpolit\"] = dataframe[\"Deforestation\"] * dataframe[\"PoliticalFactors\"]\n    dataframe[\"NEW_urbdrasy\"] = dataframe[\"Urbanization\"] * dataframe[\"DrainageSystems\"]\n    dataframe[\"NEW_urbdeter\"] = dataframe[\"Urbanization\"] * dataframe[\"DeterioratingInfrastructure\"]\n    dataframe[\"NEW_urbinadeq\"] = dataframe[\"Urbanization\"] * dataframe[\"InadequatePlanning\"]\n    dataframe[\"NEW_clmagr\"] = dataframe[\"ClimateChange\"] * dataframe[\"AgriculturalPractices\"]\n    dataframe[\"NEW_damdeter\"] = dataframe[\"DamsQuality\"] * dataframe[\"DeterioratingInfrastructure\"]\n    dataframe[\"NEW_dampop\"] = dataframe[\"DamsQuality\"] * dataframe[\"PopulationScore\"]\n    dataframe[\"NEW_popinadeq\"] = dataframe[\"PopulationScore\"] * dataframe[\"InadequatePlanning\"]\n    dataframe[\"NEW_inadeqpolit\"] = dataframe[\"InadequatePlanning\"] * dataframe[\"PoliticalFactors\"]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.752442Z","iopub.execute_input":"2024-05-22T22:06:49.752743Z","iopub.status.idle":"2024-05-22T22:06:49.762583Z","shell.execute_reply.started":"2024-05-22T22:06:49.752717Z","shell.execute_reply":"2024-05-22T22:06:49.761634Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"add_features(tr)\ntr.shape","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.763986Z","iopub.execute_input":"2024-05-22T22:06:49.764346Z","iopub.status.idle":"2024-05-22T22:06:49.826837Z","shell.execute_reply.started":"2024-05-22T22:06:49.764311Z","shell.execute_reply":"2024-05-22T22:06:49.825848Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> Since the quantiles of the variables are not very sharp and each variable is close, we did not derive categorical variables from these variables.\n\n<span style=\"font-size:18px;\"> Instead, we derived new numeric variables by interacting them with each other. \n\n<span style=\"font-size:18px;\"> Cause we are adding new variables, we do some operations again. </span>","metadata":{}},{"cell_type":"code","source":"check_df(tr)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:49.828176Z","iopub.execute_input":"2024-05-22T22:06:49.828565Z","iopub.status.idle":"2024-05-22T22:06:52.201097Z","shell.execute_reply.started":"2024-05-22T22:06:49.828529Z","shell.execute_reply":"2024-05-22T22:06:52.199861Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 2.3 Data Preprocessing with New Variables","metadata":{}},{"cell_type":"code","source":"cat_cols, num_cols, cat_but_car = grab_col_names(tr)\nnum_cols = [col for col in num_cols if col not in (\"FloodProbability\", \"id\")]","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:52.202395Z","iopub.execute_input":"2024-05-22T22:06:52.202688Z","iopub.status.idle":"2024-05-22T22:06:52.778648Z","shell.execute_reply.started":"2024-05-22T22:06:52.202664Z","shell.execute_reply":"2024-05-22T22:06:52.77767Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# target analysis of numerical variables\nfor col in num_cols:\n    target_summary_with_num(tr, \"FloodProbability\", col)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:52.780063Z","iopub.execute_input":"2024-05-22T22:06:52.780818Z","iopub.status.idle":"2024-05-22T22:06:53.898776Z","shell.execute_reply.started":"2024-05-22T22:06:52.78076Z","shell.execute_reply":"2024-05-22T22:06:53.897788Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\">  We check for outliers and suppress outliers. </span>","metadata":{}},{"cell_type":"code","source":"for col in tr.columns:\n    print(col, check_outlier(tr, col, 0.05, 0.95))\n    if check_outlier(tr, col):\n        replace_with_thresholds(tr, col)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:53.900087Z","iopub.execute_input":"2024-05-22T22:06:53.900472Z","iopub.status.idle":"2024-05-22T22:06:58.449054Z","shell.execute_reply.started":"2024-05-22T22:06:53.900434Z","shell.execute_reply":"2024-05-22T22:06:58.448197Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> After suppression, we analyze outliers again.</span>","metadata":{}},{"cell_type":"code","source":"for col in num_cols:\n    print(col, check_outlier(tr, col, 0.05, 0.95))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:58.450117Z","iopub.execute_input":"2024-05-22T22:06:58.450398Z","iopub.status.idle":"2024-05-22T22:06:59.687599Z","shell.execute_reply.started":"2024-05-22T22:06:58.450374Z","shell.execute_reply":"2024-05-22T22:06:59.686594Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 2.4 StandardScaller\n\n\n<span style=\"font-size:18px;\">Once all outliers have been suppressed, we can proceed with standardization. \n\n* <span style=\"font-size:18px;\"> Since we do not have categorical variables, we do not do one-hot-encoding.\n* <span style=\"font-size:18px;\"> For numeric variables, we continue with standard-scaller.</span>","metadata":{}},{"cell_type":"code","source":"X_scaled = StandardScaler().fit_transform(tr[num_cols])\ntr[num_cols] = pd.DataFrame(X_scaled, columns=tr[num_cols].columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:06:59.689101Z","iopub.execute_input":"2024-05-22T22:06:59.689715Z","iopub.status.idle":"2024-05-22T22:07:00.790455Z","shell.execute_reply.started":"2024-05-22T22:06:59.689677Z","shell.execute_reply":"2024-05-22T22:07:00.789359Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"y = tr[\"FloodProbability\"]\nX = tr.drop([\"FloodProbability\"], axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:00.791845Z","iopub.execute_input":"2024-05-22T22:07:00.792264Z","iopub.status.idle":"2024-05-22T22:07:00.989873Z","shell.execute_reply.started":"2024-05-22T22:07:00.792229Z","shell.execute_reply":"2024-05-22T22:07:00.989009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> # 2.5 DataPreproccessing Fonction \n\n<span style=\"font-size:18px;\"> Let's put all these meaningful operations in a function so that we don't have to do the same operations on the test dataset.  </span>","metadata":{}},{"cell_type":"code","source":"def flood_data_prep(dataframe,graphs=True):\n    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n    num_cols = [col for col in num_cols if col not in (\"FloodProbability\", \"id\")]\n    \n    # Analysis of num_cols with graphics\n    if graphs:\n        plt.figure(figsize=(20, 20))\n        for col in num_cols:\n            plt.subplot(7, 3, num_cols.index(col) + 1)\n            sns.histplot(dataframe[col], bins=20)\n            plt.title(col)\n        plt.tight_layout()\n        plt.show()\n    \n    #correlation analysis of numerical variables\n    correlation_matrix(dataframe, num_cols)\n    \n    # adding new features\n    add_features(dataframe)\n    \n    cat_cols, num_cols, cat_but_car = grab_col_names(dataframe)\n    num_cols = [col for col in num_cols if col not in (\"FloodProbability\", \"id\")]\n        \n    # checking suppression of outliers\n    for col in dataframe.columns:\n        print(col, check_outlier(dataframe, col, 0.05, 0.95))\n        if check_outlier(dataframe, col):\n            replace_with_thresholds(dataframe, col)\n        \n    # StandardScaller\n    X_scaled = StandardScaler().fit_transform(dataframe[num_cols])\n    dataframe[num_cols] = pd.DataFrame(X_scaled, columns=dataframe[num_cols].columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:00.991168Z","iopub.execute_input":"2024-05-22T22:07:00.991882Z","iopub.status.idle":"2024-05-22T22:07:01.001322Z","shell.execute_reply.started":"2024-05-22T22:07:00.991842Z","shell.execute_reply":"2024-05-22T22:07:01.000186Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 3. Model for r2 Score","metadata":{}},{"cell_type":"code","source":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:01.007428Z","iopub.execute_input":"2024-05-22T22:07:01.007898Z","iopub.status.idle":"2024-05-22T22:07:01.653274Z","shell.execute_reply.started":"2024-05-22T22:07:01.007868Z","shell.execute_reply":"2024-05-22T22:07:01.6522Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import r2_score","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:01.6545Z","iopub.execute_input":"2024-05-22T22:07:01.654857Z","iopub.status.idle":"2024-05-22T22:07:01.659092Z","shell.execute_reply.started":"2024-05-22T22:07:01.654827Z","shell.execute_reply":"2024-05-22T22:07:01.658122Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(X_train,y_train)\ny_pred_lr = lr.predict(X_test)\nr2 = r2_score(y_test,y_pred_lr)\nprint(r2)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:01.660435Z","iopub.execute_input":"2024-05-22T22:07:01.660732Z","iopub.status.idle":"2024-05-22T22:07:03.922443Z","shell.execute_reply.started":"2024-05-22T22:07:01.660698Z","shell.execute_reply":"2024-05-22T22:07:03.921423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:18px;\"> When we operated with the r2 score on the Train dataset, we found a value of approximately 0.84. \n\n<span style=\"font-size:18px;\"> Now let's do these operations on the test data that the model never sees.</span>","metadata":{}},{"cell_type":"markdown","source":"# 4. Prediction on test data\n\n<span style=\"font-size:18px;\"> It will be easier for us to work on the test dataset because we have done our preliminary preparations and defined the necessary functions. The operations we will do are as follows: \n\n* <span style=\"font-size:18px;\"> 1. Examine and prepare the data with the \"flood_data_prep\" function.\n* <span style=\"font-size:18px;\"> 2. Make predictions for the test dataset.</span>","metadata":{}},{"cell_type":"code","source":"flood_data_prep(ts)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:03.923752Z","iopub.execute_input":"2024-05-22T22:07:03.92438Z","iopub.status.idle":"2024-05-22T22:07:25.381474Z","shell.execute_reply.started":"2024-05-22T22:07:03.924344Z","shell.execute_reply":"2024-05-22T22:07:25.380519Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# check again    \nfor col in num_cols:\n    print(col, check_outlier(ts, col, 0.05, 0.95))","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:25.38288Z","iopub.execute_input":"2024-05-22T22:07:25.383269Z","iopub.status.idle":"2024-05-22T22:07:26.256017Z","shell.execute_reply.started":"2024-05-22T22:07:25.383231Z","shell.execute_reply":"2024-05-22T22:07:26.254947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"X_scaled = StandardScaler().fit_transform(ts[num_cols])\nts[num_cols] = pd.DataFrame(X_scaled, columns=ts[num_cols].columns)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:26.257465Z","iopub.execute_input":"2024-05-22T22:07:26.257901Z","iopub.status.idle":"2024-05-22T22:07:26.99311Z","shell.execute_reply.started":"2024-05-22T22:07:26.257863Z","shell.execute_reply":"2024-05-22T22:07:26.99216Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ts.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:08:48.930222Z","iopub.execute_input":"2024-05-22T22:08:48.930933Z","iopub.status.idle":"2024-05-22T22:08:48.95288Z","shell.execute_reply.started":"2024-05-22T22:08:48.930899Z","shell.execute_reply":"2024-05-22T22:08:48.951732Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = LinearRegression()\nmodel.fit(X, y)\npredictions = model.predict(ts)\ndictionary = {\"id\":ts[\"id\"], \"FloodProbability\":predictions}\ndfSubmission = pd.DataFrame(dictionary)\ndfSubmission.head()","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:26.99439Z","iopub.execute_input":"2024-05-22T22:07:26.994815Z","iopub.status.idle":"2024-05-22T22:07:29.763995Z","shell.execute_reply.started":"2024-05-22T22:07:26.994752Z","shell.execute_reply":"2024-05-22T22:07:29.762838Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# 5. CONCLUSION","metadata":{}},{"cell_type":"code","source":"dfSubmission.to_csv(\"FloodProbability.csv\", index=False)","metadata":{"execution":{"iopub.status.busy":"2024-05-22T22:07:29.765527Z","iopub.execute_input":"2024-05-22T22:07:29.765969Z","iopub.status.idle":"2024-05-22T22:07:31.42339Z","shell.execute_reply.started":"2024-05-22T22:07:29.765932Z","shell.execute_reply":"2024-05-22T22:07:31.422333Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"<span style=\"font-size:20px;\"> We also made our prediction for the test dataset and transferred it to the submission file.\n\n<span style=\"font-size:20px;\"> Thank you for following this section and I hope it has been a useful and inspiring work for you as well. </span>","metadata":{}}]}